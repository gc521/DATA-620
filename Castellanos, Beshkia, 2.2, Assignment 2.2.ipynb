{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ed5b1e",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f64456",
   "metadata": {},
   "source": [
    "#### Assignment: \n",
    "2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd7c82",
   "metadata": {},
   "source": [
    "\n",
    "#### Team: \n",
    "Gabriel Castellanos,  Beshkia Kvarnstrom \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca77a6d",
   "metadata": {},
   "source": [
    "##### Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfee80e",
   "metadata": {},
   "source": [
    "This dataset looks at votes at aggregated at the precinct level for the US House of Representatives for all 50 states. It was obtained and loaded as a csv, and will be converted to a padatas Dataframe. From there, we can look at the centrality between nodes to see which precincts share simmilar voting trends, or even which states have simillar voting trends. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c521f54",
   "metadata": {},
   "source": [
    "#### Data Plan:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06165c81",
   "metadata": {},
   "source": [
    "After the data is read into a pandas data frame, we would load additional libraries and packages into our environment: networkx, numpy, math, and matplotlib. We then need to drop any variables/columns that we do not wish to use for analysis. In our case, each node/row contains several columns, so this step requires us to further in on our research question/topic of interest so we can decide which varibales would be the most useful for analysis. After we create a class instance, we would aim to create a directed graph and use a the centrality measure of said directed graph to analyze voting trends between states and precincts. One of the attributes included in the dataset is gender, so we can see if a given gender is more likely to vote for a person within a given state/precinct. \n",
    "\n",
    "More precisely, this can be done by iterating through each row withing the csv and iterating through the columns of each row to add not only the nodes we are intersted in, but the attributes as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
